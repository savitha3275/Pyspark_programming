{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij6qSF9u4ksd",
        "outputId": "7984ff53-42a3-4de6-d49b-63dd857d6c17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark UI: http://f703e4d3b65d:4040\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "import random, time\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"StreamPulse-ExecutionArchitecture\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"8\") \\\n",
        "    .config(\"spark.sql.adaptive.enabled\", \"false\") \\\n",
        "    .config(\"spark.sql.autoBroadcastJoinThreshold\", \"-1\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(f\"Spark UI: {spark.sparkContext.uiWebUrl}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud_wKEtP422y",
        "outputId": "c54cda7a-0017-4a4e-96f7-ca87dfc19aa7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.5.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "Downloading pyngrok-7.5.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Kill any existing tunnels (safe reset)\n",
        "ngrok.kill()\n",
        "\n",
        "# Authenticate ngrok with your authtoken\n",
        "# Replace \"YOUR_NGROK_AUTHTOKEN_HERE\" with your actual ngrok authtoken from https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "ngrok.set_auth_token(\"3AJU04MhqRelI0tcdTT9eWDNJ4H_3h7dhZfh3ggHaBQGhu4WV\")\n",
        "\n",
        "# Open tunnel to Spark UI port 4040\n",
        "public_url = ngrok.connect(4040)\n",
        "\n",
        "print(\"Open this URL in your browser:\")\n",
        "print(public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgOg1z485drM",
        "outputId": "a699a64e-b357-4812-90fc-4dc8090c8def"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-02-28T20:28:50+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Open this URL in your browser:\n",
            "NgrokTunnel: \"https://symphonically-unexiled-brice.ngrok-free.dev\" -> \"http://localhost:4040\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.range(1000000).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLHxZYVJ8YqU",
        "outputId": "dbc00f53-5703-4961-b846-8659a0b4be00"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random.seed(42)\n",
        "\n",
        "# Listening events\n",
        "listen_data = [(f\"EVT-{i:07d}\", f\"USR-{random.randint(1,100000):06d}\",\n",
        "                f\"TRK-{random.randint(1,50000):05d}\",\n",
        "                random.choice([\"mobile\",\"desktop\",\"tablet\",\"speaker\",\"tv\"]),\n",
        "                random.choice([\"free\",\"premium\",\"family\",\"student\"]),\n",
        "                random.randint(10, 360),\n",
        "                random.choice([True, False]),\n",
        "                __builtins__.round(random.uniform(0.002, 0.015), 4))\n",
        "               for i in range(800000)]\n",
        "\n",
        "events = spark.createDataFrame(listen_data,\n",
        "    [\"event_id\",\"user_id\",\"track_id\",\"device\",\"tier\",\"duration\",\"completed\",\"revenue\"])\n",
        "events.write.parquet(\"lab_arch/events\", mode=\"overwrite\")\n",
        "\n",
        "# Track catalog\n",
        "track_data = [(f\"TRK-{i:05d}\", random.choice([\"Pop\",\"Rock\",\"Jazz\",\"Hip-Hop\",\"Electronic\",\"R&B\",\"Country\",\"Classical\"]),\n",
        "               random.choice([\"Major Label\",\"Indie\",\"Self-Published\"]))\n",
        "              for i in range(1, 50001)]\n",
        "tracks = spark.createDataFrame(track_data, [\"track_id\",\"genre\",\"label\"])\n",
        "tracks.write.parquet(\"lab_arch/tracks\", mode=\"overwrite\")\n",
        "\n",
        "events = spark.read.parquet(\"lab_arch/events\")\n",
        "tracks = spark.read.parquet(\"lab_arch/tracks\")\n",
        "\n",
        "print(f\"Events: {events.count()} | Tracks: {tracks.count()}\")\n",
        "print(f\"Event partitions: {events.rdd.getNumPartitions()}\")\n",
        "print(f\"Track partitions: {tracks.rdd.getNumPartitions()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBOejKnk9N9c",
        "outputId": "e1d8bf81-1d05-4bcb-f5f1-8eb5b3de4ac5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Events: 800000 | Tracks: 50000\n",
            "Event partitions: 2\n",
            "Track partitions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline 1: filter + select + withColumn (narrow only)\n",
        "pipeline1 = events \\\n",
        "    .filter(col(\"completed\") == True) \\\n",
        "    .filter(col(\"duration\") > 60) \\\n",
        "    .select(\"event_id\", \"user_id\", \"device\", \"duration\", \"revenue\") \\\n",
        "    .withColumn(\"revenue_cents\", (col(\"revenue\") * 100).cast(\"int\"))\n"
      ],
      "metadata": {
        "id": "dvbMgwQS-V8q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline1.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqPQ3DUd-Xai",
        "outputId": "caf28695-ca38-4d47-cbea-81da07a67249"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(1) Project [event_id#17, user_id#18, device#20, duration#22L, revenue#24, cast((revenue#24 * 100.0) as int) AS revenue_cents#48]\n",
            "+- *(1) Filter (((isnotnull(completed#23) AND isnotnull(duration#22L)) AND completed#23) AND (duration#22L > 60))\n",
            "   +- *(1) ColumnarToRow\n",
            "      +- FileScan parquet [event_id#17,user_id#18,device#20,duration#22L,completed#23,revenue#24] Batched: true, DataFilters: [isnotnull(completed#23), isnotnull(duration#22L), completed#23, (duration#22L > 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/lab_arch/events], PartitionFilters: [], PushedFilters: [IsNotNull(completed), IsNotNull(duration), EqualTo(completed,true), GreaterThan(duration,60)], ReadSchema: struct<event_id:string,user_id:string,device:string,duration:bigint,completed:boolean,revenue:dou...\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline1.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmVaNf8m-pNL",
        "outputId": "a265971b-9209-4dc2-cbf8-604158d4ca3c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "342109"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline1.rdd.getNumPartitions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d9DfOdUAYP6",
        "outputId": "6f11af52-d62d-42e4-968d-a70dc298edb1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline1.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn60zmfUBJv3",
        "outputId": "8dbee097-c58f-45d9-a9db-369a9c3429fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Project [unresolvedstarwithcolumns(revenue_cents, cast('`*`('revenue, 100) as int), None)]\n",
            "+- Project [event_id#17, user_id#18, device#20, duration#22L, revenue#24]\n",
            "   +- Filter (duration#22L > cast(60 as bigint))\n",
            "      +- Filter (completed#23 = true)\n",
            "         +- Relation [event_id#17,user_id#18,track_id#19,device#20,tier#21,duration#22L,completed#23,revenue#24] parquet\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "event_id: string, user_id: string, device: string, duration: bigint, revenue: double, revenue_cents: int\n",
            "Project [event_id#17, user_id#18, device#20, duration#22L, revenue#24, cast((revenue#24 * cast(100 as double)) as int) AS revenue_cents#48]\n",
            "+- Project [event_id#17, user_id#18, device#20, duration#22L, revenue#24]\n",
            "   +- Filter (duration#22L > cast(60 as bigint))\n",
            "      +- Filter (completed#23 = true)\n",
            "         +- Relation [event_id#17,user_id#18,track_id#19,device#20,tier#21,duration#22L,completed#23,revenue#24] parquet\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Project [event_id#17, user_id#18, device#20, duration#22L, revenue#24, cast((revenue#24 * 100.0) as int) AS revenue_cents#48]\n",
            "+- Filter ((isnotnull(completed#23) AND isnotnull(duration#22L)) AND (completed#23 AND (duration#22L > 60)))\n",
            "   +- Relation [event_id#17,user_id#18,track_id#19,device#20,tier#21,duration#22L,completed#23,revenue#24] parquet\n",
            "\n",
            "== Physical Plan ==\n",
            "*(1) Project [event_id#17, user_id#18, device#20, duration#22L, revenue#24, cast((revenue#24 * 100.0) as int) AS revenue_cents#48]\n",
            "+- *(1) Filter (((isnotnull(completed#23) AND isnotnull(duration#22L)) AND completed#23) AND (duration#22L > 60))\n",
            "   +- *(1) ColumnarToRow\n",
            "      +- FileScan parquet [event_id#17,user_id#18,device#20,duration#22L,completed#23,revenue#24] Batched: true, DataFilters: [isnotnull(completed#23), isnotnull(duration#22L), completed#23, (duration#22L > 60)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/lab_arch/events], PartitionFilters: [], PushedFilters: [IsNotNull(completed), IsNotNull(duration), EqualTo(completed,true), GreaterThan(duration,60)], ReadSchema: struct<event_id:string,user_id:string,device:string,duration:bigint,completed:boolean,revenue:dou...\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.setJobDescription(\"PIPELINE_1_COUNT\")\n",
        "pipeline1.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJQL53teCHoP",
        "outputId": "42855592-8cb1-4585-c07e-86de0d743cde"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "342109"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline2 = events \\\n",
        "    .filter(col(\"completed\") == True) \\\n",
        "    .groupBy(\"device\") \\\n",
        "    .agg(count(\"*\").alias(\"plays\"),\n",
        "         sum(\"revenue\").alias(\"total_rev\"))"
      ],
      "metadata": {
        "id": "b4DaEvGeEHbI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline2.explain()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT2h18wNEr8v",
        "outputId": "ce9205f8-3842-4d25-c2cd-b1a220665b05"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(2) HashAggregate(keys=[device#20], functions=[count(1), sum(revenue#24)])\n",
            "+- Exchange hashpartitioning(device#20, 8), ENSURE_REQUIREMENTS, [plan_id=258]\n",
            "   +- *(1) HashAggregate(keys=[device#20], functions=[partial_count(1), partial_sum(revenue#24)])\n",
            "      +- *(1) Project [device#20, revenue#24]\n",
            "         +- *(1) Filter (isnotnull(completed#23) AND completed#23)\n",
            "            +- *(1) ColumnarToRow\n",
            "               +- FileScan parquet [device#20,completed#23,revenue#24] Batched: true, DataFilters: [isnotnull(completed#23), completed#23], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/lab_arch/events], PartitionFilters: [], PushedFilters: [IsNotNull(completed), EqualTo(completed,true)], ReadSchema: struct<device:string,completed:boolean,revenue:double>\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.setJobDescription(\"PIPELINE_2_GROUPBY_DEVICE\")\n",
        "pipeline2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT_z5wPlEe-v",
        "outputId": "fa19b4ef-949a-4f42-cca4-534814086db7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----+-----------------+\n",
            "| device|plays|        total_rev|\n",
            "+-------+-----+-----------------+\n",
            "| tablet|80227|679.3329999999964|\n",
            "|speaker|79783|678.1191999999917|\n",
            "|     tv|79964|680.2651999999941|\n",
            "| mobile|80767|686.3548999999934|\n",
            "|desktop|79729|676.4081999999994|\n",
            "+-------+-----+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric                      | Value                        |\n",
        "| --------------------------- | ---------------------------- |\n",
        "| Jobs                        | 1 main job (others internal) |\n",
        "| Stages                      | 2                            |\n",
        "| Stage 1 Tasks               | 2                            |\n",
        "| Stage 2 Tasks               | 1                            |\n",
        "| Shuffle write               | 609 B                        |\n",
        "| Shuffle read                | 609 B                        |\n",
        "| Shuffle boundary created by | groupBy                      |\n"
      ],
      "metadata": {
        "id": "gRdbkHpVGhKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline 3a: SortMerge Join (autoBroadcast disabled)\n",
        "start = time.time()\n",
        "joined_sm = events.join(tracks, \"track_id\")\n",
        "result_sm = joined_sm.groupBy(\"genre\").agg(sum(\"revenue\").alias(\"total_rev\"))\n",
        "result_sm.explain()\n",
        "result_sm.show()\n",
        "time_sm = time.time() - start\n",
        "print(f\"SortMerge join time: {time_sm:.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_KUKnzIGiXA",
        "outputId": "6f5a5914-2e42-4012-9d59-05e8bdca922e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(6) HashAggregate(keys=[genre#26], functions=[sum(revenue#24)])\n",
            "+- Exchange hashpartitioning(genre#26, 8), ENSURE_REQUIREMENTS, [plan_id=404]\n",
            "   +- *(5) HashAggregate(keys=[genre#26], functions=[partial_sum(revenue#24)])\n",
            "      +- *(5) Project [revenue#24, genre#26]\n",
            "         +- *(5) SortMergeJoin [track_id#19], [track_id#25], Inner\n",
            "            :- *(2) Sort [track_id#19 ASC NULLS FIRST], false, 0\n",
            "            :  +- Exchange hashpartitioning(track_id#19, 8), ENSURE_REQUIREMENTS, [plan_id=386]\n",
            "            :     +- *(1) Filter isnotnull(track_id#19)\n",
            "            :        +- *(1) ColumnarToRow\n",
            "            :           +- FileScan parquet [track_id#19,revenue#24] Batched: true, DataFilters: [isnotnull(track_id#19)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/lab_arch/events], PartitionFilters: [], PushedFilters: [IsNotNull(track_id)], ReadSchema: struct<track_id:string,revenue:double>\n",
            "            +- *(4) Sort [track_id#25 ASC NULLS FIRST], false, 0\n",
            "               +- Exchange hashpartitioning(track_id#25, 8), ENSURE_REQUIREMENTS, [plan_id=395]\n",
            "                  +- *(3) Filter isnotnull(track_id#25)\n",
            "                     +- *(3) ColumnarToRow\n",
            "                        +- FileScan parquet [track_id#25,genre#26] Batched: true, DataFilters: [isnotnull(track_id#25)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/lab_arch/tracks], PartitionFilters: [], PushedFilters: [IsNotNull(track_id)], ReadSchema: struct<track_id:string,genre:string>\n",
            "\n",
            "\n",
            "+----------+-----------------+\n",
            "|     genre|        total_rev|\n",
            "+----------+-----------------+\n",
            "|      Rock|838.1191000000026|\n",
            "| Classical| 845.793000000001|\n",
            "|       Pop|844.4322000000017|\n",
            "|      Jazz|849.4741000000023|\n",
            "|Electronic|852.3180000000009|\n",
            "|       R&B| 842.639500000001|\n",
            "|   Country|834.7105000000024|\n",
            "|   Hip-Hop|882.7481000000005|\n",
            "+----------+-----------------+\n",
            "\n",
            "SortMerge join time: 8.30s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.setJobDescription(\"SORTMERGE_JOIN\")"
      ],
      "metadata": {
        "id": "uyxiu3pkG6-J"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline 3b: Broadcast Join\n",
        "start = time.time()\n",
        "joined_bc = events.join(broadcast(tracks), \"track_id\")\n",
        "result_bc = joined_bc.groupBy(\"genre\").agg(sum(\"revenue\").alias(\"total_rev\"))\n",
        "result_bc.explain()\n",
        "result_bc.show()\n",
        "time_bc = time.time() - start\n",
        "print(f\"Broadcast join time: {time_bc:.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8gWkpmbHbzz",
        "outputId": "b5144b76-bda8-4217-ddbd-6c57c21fd7ca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Physical Plan ==\n",
            "*(3) HashAggregate(keys=[genre#26], functions=[sum(revenue#24)])\n",
            "+- Exchange hashpartitioning(genre#26, 8), ENSURE_REQUIREMENTS, [plan_id=633]\n",
            "   +- *(2) HashAggregate(keys=[genre#26], functions=[partial_sum(revenue#24)])\n",
            "      +- *(2) Project [revenue#24, genre#26]\n",
            "         +- *(2) BroadcastHashJoin [track_id#19], [track_id#25], Inner, BuildRight, false\n",
            "            :- *(2) Filter isnotnull(track_id#19)\n",
            "            :  +- *(2) ColumnarToRow\n",
            "            :     +- FileScan parquet [track_id#19,revenue#24] Batched: true, DataFilters: [isnotnull(track_id#19)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/lab_arch/events], PartitionFilters: [], PushedFilters: [IsNotNull(track_id)], ReadSchema: struct<track_id:string,revenue:double>\n",
            "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=627]\n",
            "               +- *(1) Filter isnotnull(track_id#25)\n",
            "                  +- *(1) ColumnarToRow\n",
            "                     +- FileScan parquet [track_id#25,genre#26] Batched: true, DataFilters: [isnotnull(track_id#25)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/lab_arch/tracks], PartitionFilters: [], PushedFilters: [IsNotNull(track_id)], ReadSchema: struct<track_id:string,genre:string>\n",
            "\n",
            "\n",
            "+----------+-----------------+\n",
            "|     genre|        total_rev|\n",
            "+----------+-----------------+\n",
            "|      Rock|838.1190999999797|\n",
            "|       Pop|844.4321999999842|\n",
            "| Classical|845.7929999999835|\n",
            "|Electronic|852.3179999999829|\n",
            "|      Jazz|849.4740999999784|\n",
            "|       R&B|842.6394999999836|\n",
            "|   Country|834.7104999999915|\n",
            "|   Hip-Hop|882.7480999999837|\n",
            "+----------+-----------------+\n",
            "\n",
            "Broadcast join time: 5.35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.setJobDescription(\"PIPELINE_3A_SORTMERGE\")\n",
        "result_sm.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x04KuddIHfX4",
        "outputId": "870e0bd2-75b8-4e65-fd60-7339d8fca77c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+\n",
            "|     genre|        total_rev|\n",
            "+----------+-----------------+\n",
            "|      Rock|838.1191000000026|\n",
            "| Classical| 845.793000000001|\n",
            "|       Pop|844.4322000000017|\n",
            "|      Jazz|849.4741000000023|\n",
            "|Electronic|852.3180000000009|\n",
            "|       R&B| 842.639500000001|\n",
            "|   Country|834.7105000000024|\n",
            "|   Hip-Hop|882.7481000000005|\n",
            "+----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric                | Value         |\n",
        "| --------------------- | ------------- |\n",
        "| Total stages          | 4             |\n",
        "| Max tasks in a stage  | 8             |\n",
        "| Largest shuffle write | 8.9 MiB       |\n",
        "| Largest shuffle read  | 9.4 MiB       |\n",
        "| Slowest stage         | Stage 41 (2s) |\n",
        "| Total runtime         | ~4s           |\n"
      ],
      "metadata": {
        "id": "BlaVpR5bIyfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.setJobDescription(\"PIPELINE_3B_BROADCAST\")\n",
        "result_bc.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhIlZhf9IQ0S",
        "outputId": "dc442405-742d-4ff4-e75b-3271aa2a84ea"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------------+\n",
            "|     genre|        total_rev|\n",
            "+----------+-----------------+\n",
            "|      Rock|838.1190999999797|\n",
            "|       Pop|844.4321999999842|\n",
            "| Classical|845.7929999999835|\n",
            "|Electronic|852.3179999999829|\n",
            "|      Jazz|849.4740999999784|\n",
            "|       R&B|842.6394999999836|\n",
            "|   Country|834.7104999999915|\n",
            "|   Hip-Hop|882.7480999999837|\n",
            "+----------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Stage | Duration | Tasks | What It’s Doing                                 |\n",
        "| ----- | -------- | ----- | ----------------------------------------------- |\n",
        "| 22    | 0.2 s    | 1     | Small table (tracks) broadcast to all executors |\n",
        "| 23    | 2 s      | 2     | Join executed (no shuffle!)                     |\n",
        "| 24    | 0.1 s    | 4     | GroupBy(genre) aggregation                      |\n",
        "| 25    | 0.1 s    | 3     | Final aggregation + `.show()`                   |\n"
      ],
      "metadata": {
        "id": "8CXOxbF9JHTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric              | SortMerge Join | Broadcast Join |\n",
        "| ------------------- | -------------- | -------------- |\n",
        "| Total stages        | 4              | 4              |\n",
        "| Tasks in join stage | 8              | 2              |\n",
        "| Shuffle write       | 8.9 MiB        | 0–1 KiB        |\n",
        "| Shuffle read        | 9.4 MiB        | 0–1 KiB        |\n",
        "| Slowest stage       | Stage 41 (2s)  | Stage 23 (2s)  |\n",
        "| Runtime             | ~4 s           | ~2 s           |\n"
      ],
      "metadata": {
        "id": "UOSNOJFIJfNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.setJobDescription(\"PIPELINE_4_MULTIACTION_WITHOUT_CACHE\")\n",
        "enriched = events.join(broadcast(tracks), \"track_id\")\n",
        "\n",
        "# Action 1\n",
        "start = time.time()\n",
        "print(f\"Total: {enriched.count()}\")\n",
        "t1 = time.time() - start\n",
        "\n",
        "# Action 2\n",
        "start = time.time()\n",
        "enriched.groupBy(\"genre\").agg(count(\"*\")).show()\n",
        "t2 = time.time() - start\n",
        "\n",
        "# Action 3\n",
        "start = time.time()\n",
        "enriched.groupBy(\"device\",\"genre\").agg(avg(\"duration\")).show()\n",
        "t3 = time.time() - start\n",
        "\n",
        "print(f\"\\nWithout cache: {t1:.2f}s + {t2:.2f}s + {t3:.2f}s = {t1+t2+t3:.2f}s total\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7yyDiT3K4Zp",
        "outputId": "2f20d1c9-ff1b-4616-ee63-00f581b82748"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 800000\n",
            "+----------+--------+\n",
            "|     genre|count(1)|\n",
            "+----------+--------+\n",
            "|      Rock|   98754|\n",
            "|       Pop|   99445|\n",
            "| Classical|   99604|\n",
            "|Electronic|  100465|\n",
            "|      Jazz|  100341|\n",
            "|       R&B|   99204|\n",
            "|   Country|   98439|\n",
            "|   Hip-Hop|  103748|\n",
            "+----------+--------+\n",
            "\n",
            "+-------+----------+------------------+\n",
            "| device|     genre|     avg(duration)|\n",
            "+-------+----------+------------------+\n",
            "| mobile|Electronic| 185.7190280971903|\n",
            "| tablet| Classical|185.67922918653085|\n",
            "| tablet|       R&B|183.03205355784348|\n",
            "| mobile|      Rock| 183.8533252353477|\n",
            "|desktop|   Country|184.96477062332852|\n",
            "|speaker|   Hip-Hop|184.31145963629365|\n",
            "| mobile|   Country|185.40454930912355|\n",
            "|speaker|   Country|185.61704718417047|\n",
            "|speaker|Electronic|185.82959396406235|\n",
            "|speaker| Classical| 184.6383702049929|\n",
            "|     tv|      Jazz|185.31201665675192|\n",
            "|desktop|      Rock|185.32751555623008|\n",
            "|     tv|       Pop| 184.3024787571019|\n",
            "|     tv|   Hip-Hop| 184.2873852102465|\n",
            "| mobile|       R&B| 183.9146027342976|\n",
            "|speaker|      Rock|185.63380353414473|\n",
            "| tablet|       Pop|185.00545824443012|\n",
            "|speaker|       R&B|183.59592771697632|\n",
            "|desktop|       Pop| 185.7435716446506|\n",
            "| tablet|   Hip-Hop|184.71280630105016|\n",
            "+-------+----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "Without cache: 0.85s + 1.38s + 1.50s = 3.73s total\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Job / Stage | Description                      | Duration    | Tasks           | Notes                                   |\n",
        "| ----------- | -------------------------------- | ----------- | --------------- | --------------------------------------- |\n",
        "| Job 50      | showString (avg by device+genre) | 0.2 s       | 4/4 (2 skipped) | Last action                             |\n",
        "| Job 49      | showString (groupBy genre)       | 1.0 s       | 2/2             | Second action                           |\n",
        "| Job 48-42   | Various preparatory tasks        | 0.05–0.85 s | 1–2 tasks each  | Each action triggers full recomputation |\n"
      ],
      "metadata": {
        "id": "1gsqJimSLi8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sparkContext.setJobDescription(\"PIPELINE_4_MULTIACTION_WITH_CACHE\")\n",
        "\n",
        "enriched = events.join(broadcast(tracks), \"track_id\")\n",
        "enriched.cache()\n",
        "\n",
        "# Action 1 (materializes cache)\n",
        "start = time.time()\n",
        "print(f\"Total: {enriched.count()}\")\n",
        "t1c = time.time() - start\n",
        "\n",
        "# Action 2\n",
        "start = time.time()\n",
        "enriched.groupBy(\"genre\").agg(count(\"*\")).show()\n",
        "t2c = time.time() - start\n",
        "\n",
        "# Action 3\n",
        "start = time.time()\n",
        "enriched.groupBy(\"device\",\"genre\").agg(avg(\"duration\")).show()\n",
        "t3c = time.time() - start\n",
        "\n",
        "print(f\"\\nWith cache: {t1c:.2f}s + {t2c:.2f}s + {t3c:.2f}s = {t1c+t2c+t3c:.2f}s total\")\n",
        "\n",
        "enriched.unpersist()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpk0Dm66JQBG",
        "outputId": "efa58e7a-21b1-4b61-e97d-ef5329860fa4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total: 800000\n",
            "+----------+--------+\n",
            "|     genre|count(1)|\n",
            "+----------+--------+\n",
            "|      Rock|   98754|\n",
            "|       Pop|   99445|\n",
            "| Classical|   99604|\n",
            "|Electronic|  100465|\n",
            "|      Jazz|  100341|\n",
            "|       R&B|   99204|\n",
            "|   Country|   98439|\n",
            "|   Hip-Hop|  103748|\n",
            "+----------+--------+\n",
            "\n",
            "+-------+----------+------------------+\n",
            "| device|     genre|     avg(duration)|\n",
            "+-------+----------+------------------+\n",
            "| mobile|Electronic| 185.7190280971903|\n",
            "| tablet| Classical|185.67922918653085|\n",
            "| tablet|       R&B|183.03205355784348|\n",
            "| mobile|      Rock| 183.8533252353477|\n",
            "|desktop|   Country|184.96477062332852|\n",
            "|speaker|   Hip-Hop|184.31145963629365|\n",
            "| mobile|   Country|185.40454930912355|\n",
            "|speaker|   Country|185.61704718417047|\n",
            "|speaker|Electronic|185.82959396406235|\n",
            "|speaker| Classical| 184.6383702049929|\n",
            "|     tv|      Jazz|185.31201665675192|\n",
            "|desktop|      Rock|185.32751555623008|\n",
            "|     tv|       Pop| 184.3024787571019|\n",
            "|     tv|   Hip-Hop| 184.2873852102465|\n",
            "| mobile|       R&B| 183.9146027342976|\n",
            "|speaker|      Rock|185.63380353414473|\n",
            "| tablet|       Pop|185.00545824443012|\n",
            "|speaker|       R&B|183.59592771697632|\n",
            "|desktop|       Pop| 185.7435716446506|\n",
            "| tablet|   Hip-Hop|184.71280630105016|\n",
            "+-------+----------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "With cache: 11.01s + 1.06s + 1.22s = 13.29s total\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[track_id: string, event_id: string, user_id: string, device: string, tier: string, duration: bigint, completed: boolean, revenue: double, genre: string, label: string]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Job / Stage | Description                       | Duration | Tasks           | Notes                                                    |\n",
        "| ----------- | --------------------------------- | -------- | --------------- | -------------------------------------------------------- |\n",
        "| Job 38      | PIPELINE_4_MULTIACTION_WITH_CACHE | 62 ms    | 4/4 (2 skipped) | Likely the last action (`avg(duration)` by device+genre) |\n",
        "| Job 37      | PIPELINE_4_MULTIACTION_WITH_CACHE | 0.6 s    | 2/2             | Aggregation by genre                                     |\n",
        "| Job 36      | PIPELINE_4_MULTIACTION_WITH_CACHE | 10 s     | 2/2             | **Count action** (materializes cache)                    |\n",
        "| Job 35      | PIPELINE_4_MULTIACTION_WITH_CACHE | 0.1 s    | 1/1             | Minor preparatory tasks                                  |\n"
      ],
      "metadata": {
        "id": "b6hT9ZYPK1kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Metric                 | With Cache                                     | Without Cache                    |\n",
        "| ---------------------- | ---------------------------------------------- | -------------------------------- |\n",
        "| First action duration  | 10 s                                           | 0.5 s–10 s?                      |\n",
        "| Second action duration | 0.6 s                                          | 1 s                              |\n",
        "| Third action duration  | 0.06 s                                         | 0.2 s                            |\n",
        "| Tasks executed         | Fewer (some skipped)                           | More (recomputed)                |\n",
        "| Stages saved           | Subsequent actions reuse cache                 | All stages recomputed            |\n",
        "| Shuffle usage          | Same (cached DataFrame prevents extra shuffle) | Same, but recomputed each action |\n"
      ],
      "metadata": {
        "id": "OIknQxrHLk0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import countDistinct\n",
        "\n",
        "# Set the job name for Spark UI\n",
        "spark.sparkContext.setJobDescription(\"PIPELINE_5_COMPLEX_AGG\")\n",
        "\n",
        "# Complex pipeline\n",
        "result = events \\\n",
        "    .filter(col(\"completed\") == True) \\\n",
        "    .filter(col(\"duration\") > 30) \\\n",
        "    .join(broadcast(tracks), \"track_id\") \\\n",
        "    .groupBy(\"genre\", \"device\", \"tier\") \\\n",
        "    .agg(\n",
        "        count(\"*\").alias(\"plays\"),\n",
        "        sum(\"revenue\").alias(\"total_rev\"),\n",
        "        avg(\"duration\").alias(\"avg_dur\"),\n",
        "        countDistinct(\"user_id\").alias(\"unique_users\")\n",
        "    ) \\\n",
        "    .filter(col(\"plays\") > 50) \\\n",
        "    .orderBy(col(\"total_rev\").desc())\n",
        "\n",
        "# Check the plan and results\n",
        "result.explain(True)\n",
        "result.show(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiIFcJtEJz27",
        "outputId": "9f6adcec-0851-494c-f262-fc395d5144ae"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Sort ['total_rev DESC NULLS LAST], true\n",
            "+- Filter (plays#1149L > cast(50 as bigint))\n",
            "   +- Aggregate [genre#26, device#20, tier#21], [genre#26, device#20, tier#21, count(1) AS plays#1149L, sum(revenue#24) AS total_rev#1150, avg(duration#22L) AS avg_dur#1151, count(distinct user_id#18) AS unique_users#1152L]\n",
            "      +- Project [track_id#19, event_id#17, user_id#18, device#20, tier#21, duration#22L, completed#23, revenue#24, genre#26, label#27]\n",
            "         +- Join Inner, (track_id#19 = track_id#25)\n",
            "            :- Filter (duration#22L > cast(30 as bigint))\n",
            "            :  +- Filter (completed#23 = true)\n",
            "            :     +- Relation [event_id#17,user_id#18,track_id#19,device#20,tier#21,duration#22L,completed#23,revenue#24] parquet\n",
            "            +- ResolvedHint (strategy=broadcast)\n",
            "               +- Relation [track_id#25,genre#26,label#27] parquet\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "genre: string, device: string, tier: string, plays: bigint, total_rev: double, avg_dur: double, unique_users: bigint\n",
            "Sort [total_rev#1150 DESC NULLS LAST], true\n",
            "+- Filter (plays#1149L > cast(50 as bigint))\n",
            "   +- Aggregate [genre#26, device#20, tier#21], [genre#26, device#20, tier#21, count(1) AS plays#1149L, sum(revenue#24) AS total_rev#1150, avg(duration#22L) AS avg_dur#1151, count(distinct user_id#18) AS unique_users#1152L]\n",
            "      +- Project [track_id#19, event_id#17, user_id#18, device#20, tier#21, duration#22L, completed#23, revenue#24, genre#26, label#27]\n",
            "         +- Join Inner, (track_id#19 = track_id#25)\n",
            "            :- Filter (duration#22L > cast(30 as bigint))\n",
            "            :  +- Filter (completed#23 = true)\n",
            "            :     +- Relation [event_id#17,user_id#18,track_id#19,device#20,tier#21,duration#22L,completed#23,revenue#24] parquet\n",
            "            +- ResolvedHint (strategy=broadcast)\n",
            "               +- Relation [track_id#25,genre#26,label#27] parquet\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Sort [total_rev#1150 DESC NULLS LAST], true\n",
            "+- Filter (plays#1149L > 50)\n",
            "   +- Aggregate [genre#26, device#20, tier#21], [genre#26, device#20, tier#21, count(1) AS plays#1149L, sum(revenue#24) AS total_rev#1150, avg(duration#22L) AS avg_dur#1151, count(distinct user_id#18) AS unique_users#1152L]\n",
            "      +- Project [user_id#18, device#20, tier#21, duration#22L, revenue#24, genre#26]\n",
            "         +- Join Inner, (track_id#19 = track_id#25), rightHint=(strategy=broadcast)\n",
            "            :- Project [user_id#18, track_id#19, device#20, tier#21, duration#22L, revenue#24]\n",
            "            :  +- Filter (((isnotnull(completed#23) AND isnotnull(duration#22L)) AND (completed#23 AND (duration#22L > 30))) AND isnotnull(track_id#19))\n",
            "            :     +- Relation [event_id#17,user_id#18,track_id#19,device#20,tier#21,duration#22L,completed#23,revenue#24] parquet\n",
            "            +- Project [track_id#25, genre#26]\n",
            "               +- Filter isnotnull(track_id#25)\n",
            "                  +- Relation [track_id#25,genre#26,label#27] parquet\n",
            "\n",
            "== Physical Plan ==\n",
            "*(5) Sort [total_rev#1150 DESC NULLS LAST], true, 0\n",
            "+- Exchange rangepartitioning(total_rev#1150 DESC NULLS LAST, 8), ENSURE_REQUIREMENTS, [plan_id=1792]\n",
            "   +- *(4) Filter (plays#1149L > 50)\n",
            "      +- *(4) HashAggregate(keys=[genre#26, device#20, tier#21], functions=[count(1), sum(revenue#24), avg(duration#22L), count(distinct user_id#18)], output=[genre#26, device#20, tier#21, plays#1149L, total_rev#1150, avg_dur#1151, unique_users#1152L])\n",
            "         +- Exchange hashpartitioning(genre#26, device#20, tier#21, 8), ENSURE_REQUIREMENTS, [plan_id=1787]\n",
            "            +- *(3) HashAggregate(keys=[genre#26, device#20, tier#21], functions=[merge_count(1), merge_sum(revenue#24), merge_avg(duration#22L), partial_count(distinct user_id#18)], output=[genre#26, device#20, tier#21, count#1168L, sum#1170, sum#1173, count#1174L, count#1177L])\n",
            "               +- *(3) HashAggregate(keys=[genre#26, device#20, tier#21, user_id#18], functions=[merge_count(1), merge_sum(revenue#24), merge_avg(duration#22L)], output=[genre#26, device#20, tier#21, user_id#18, count#1168L, sum#1170, sum#1173, count#1174L])\n",
            "                  +- Exchange hashpartitioning(genre#26, device#20, tier#21, user_id#18, 8), ENSURE_REQUIREMENTS, [plan_id=1782]\n",
            "                     +- *(2) HashAggregate(keys=[genre#26, device#20, tier#21, user_id#18], functions=[partial_count(1), partial_sum(revenue#24), partial_avg(duration#22L)], output=[genre#26, device#20, tier#21, user_id#18, count#1168L, sum#1170, sum#1173, count#1174L])\n",
            "                        +- *(2) Project [user_id#18, device#20, tier#21, duration#22L, revenue#24, genre#26]\n",
            "                           +- *(2) BroadcastHashJoin [track_id#19], [track_id#25], Inner, BuildRight, false\n",
            "                              :- *(2) Project [user_id#18, track_id#19, device#20, tier#21, duration#22L, revenue#24]\n",
            "                              :  +- *(2) Filter ((((isnotnull(completed#23) AND isnotnull(duration#22L)) AND completed#23) AND (duration#22L > 30)) AND isnotnull(track_id#19))\n",
            "                              :     +- *(2) ColumnarToRow\n",
            "                              :        +- FileScan parquet [user_id#18,track_id#19,device#20,tier#21,duration#22L,completed#23,revenue#24] Batched: true, DataFilters: [isnotnull(completed#23), isnotnull(duration#22L), completed#23, (duration#22L > 30), isnotnull(t..., Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/lab_arch/events], PartitionFilters: [], PushedFilters: [IsNotNull(completed), IsNotNull(duration), EqualTo(completed,true), GreaterThan(duration,30), Is..., ReadSchema: struct<user_id:string,track_id:string,device:string,tier:string,duration:bigint,completed:boolean...\n",
            "                              +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=1776]\n",
            "                                 +- *(1) Filter isnotnull(track_id#25)\n",
            "                                    +- *(1) ColumnarToRow\n",
            "                                       +- FileScan parquet [track_id#25,genre#26] Batched: true, DataFilters: [isnotnull(track_id#25)], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/lab_arch/tracks], PartitionFilters: [], PushedFilters: [IsNotNull(track_id)], ReadSchema: struct<track_id:string,genre:string>\n",
            "\n",
            "+----------+-------+-------+-----+------------------+------------------+------------+\n",
            "|     genre| device|   tier|plays|         total_rev|           avg_dur|unique_users|\n",
            "+----------+-------+-------+-----+------------------+------------------+------------+\n",
            "|   Hip-Hop|desktop| family| 2533|21.811399999999992| 196.5519147256218|        2494|\n",
            "|   Hip-Hop|     tv|   free| 2503|21.378600000000002|195.58449860167798|        2477|\n",
            "|   Hip-Hop| mobile|student| 2535|           21.3639|196.47968441814595|        2496|\n",
            "|   Hip-Hop|speaker|premium| 2486| 21.18729999999999|194.18262268704746|        2459|\n",
            "|   Hip-Hop|speaker|   free| 2487| 21.17620000000001|191.54000804181746|        2461|\n",
            "|   Hip-Hop| tablet|   free| 2466|21.133099999999985|195.19586374695865|        2429|\n",
            "|   Hip-Hop|     tv|student| 2449| 21.00370000000001|194.67946100449163|        2427|\n",
            "|   Hip-Hop| mobile|premium| 2454|20.983100000000004|193.30643846780765|        2429|\n",
            "|   Hip-Hop| mobile|   free| 2470|           20.9436| 197.1408906882591|        2439|\n",
            "|   Hip-Hop| tablet|student| 2455|20.939199999999996| 193.6920570264766|        2418|\n",
            "|   Hip-Hop|speaker|student| 2458|20.938699999999997| 193.4080553295362|        2427|\n",
            "|   Hip-Hop|desktop|premium| 2445|20.902299999999993|  195.039672801636|        2422|\n",
            "|       R&B| mobile|   free| 2448|20.890700000000002| 192.6968954248366|        2422|\n",
            "|       Pop|desktop|   free| 2415|           20.8541|195.35238095238094|        2387|\n",
            "|   Country| mobile|premium| 2405|           20.8175| 196.1904365904366|        2380|\n",
            "|Electronic|desktop| family| 2452|20.778799999999997|192.22063621533442|        2422|\n",
            "| Classical| tablet|premium| 2420|20.771200000000004|197.97231404958677|        2389|\n",
            "|Electronic|     tv|premium| 2414|20.745700000000003|190.53106876553437|        2389|\n",
            "|Electronic| mobile|   free| 2430|20.741699999999994| 194.0971193415638|        2401|\n",
            "|       R&B| mobile|student| 2420|           20.7146| 194.6512396694215|        2387|\n",
            "+----------+-------+-------+-----+------------------+------------------+------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Stage Id | Description                                                           | Tasks (Succeeded/Total) | Input    | Output   | Shuffle Read | Shuffle Write | Notes                                                            |\n",
        "| -------- | --------------------------------------------------------------------- | ----------------------- | -------- | -------- | ------------ | ------------- | ---------------------------------------------------------------- |\n",
        "| 102      | File scan + narrow transformations (filter completed & duration > 30) | 2/2                     | 8.9 MiB  | 13.5 MiB | –            | 13.5 MiB      | Reading Parquet files, applying filters. No shuffle yet.         |\n",
        "| 103      | Broadcast join with `tracks`                                          | 8/8                     | 13.5 MiB | 64.1 KiB | –            | 64.1 KiB      | Broadcast join avoids shuffle, merges `tracks` with `events`.    |\n",
        "| 104      | Aggregation (`groupBy genre, device, tier`) + final filter & order    | 8/8                     | 64.1 KiB | 64.1 KiB | –            | –             | Aggregation and ordering. Small output, likely cached in memory. |\n"
      ],
      "metadata": {
        "id": "S0FHcmg_Mrup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Observations\n",
        "\n",
        "Job Count: 1 (PIPELINE_5_COMPLEX_AGG)\n",
        "\n",
        "Stage Count: 3 (Stages 102–104)\n",
        "\n",
        "Shuffle Boundaries: None (broadcast join avoids shuffle; all transformations are either narrow or broadcast-enabled)\n",
        "\n",
        "Most Expensive Stage: Stage 102 (File scan + filters) and Stage 103 (join) dominate input size processing.\n",
        "\n",
        "Optimization: Using broadcast(tracks) avoids a full shuffle join, reducing time and shuffle write/read\n"
      ],
      "metadata": {
        "id": "I3ykGAUnMxzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StreamPulse Execution Architecture Guide\n",
        "How Spark Executes Your Code\n",
        "Step-by-Step Flow\n",
        "\n",
        "You write Python code → SparkSession receives it\n",
        "\n",
        "Catalyst optimizer creates and optimizes a logical plan\n",
        "\n",
        "Physical plan is generated\n",
        "\n",
        "DAG Scheduler breaks the plan into stages at shuffle boundaries\n",
        "\n",
        "Task Scheduler assigns tasks (one per partition per stage)\n",
        "\n",
        "Executors run tasks in parallel and return results\n",
        "\n",
        "Key Rules\n",
        "\n",
        "1 action = 1 job\n",
        "\n",
        "1 shuffle = 1 stage boundary\n",
        "\n",
        "Stages: number of shuffles + 1\n",
        "\n",
        "Tasks per stage: number of partitions\n",
        "\n",
        "Broadcast join: NO shuffle\n",
        "\n",
        "SortMerge join: 1-2 shuffles"
      ],
      "metadata": {
        "id": "3aZi2fQkNFcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 1 – Pipeline 1 (Narrow Transformations Only)\n",
        "| Job Id | Stage Id | Description      | Tasks | Input   | Output | Shuffle Read | Shuffle Write | Notes                                             |\n",
        "| ------ | -------- | ---------------- | ----- | ------- | ------ | ------------ | ------------- | ------------------------------------------------- |\n",
        "| 6      | 12       | PIPELINE_1_COUNT | 2/2   | 1.2 MiB | 118 B  | –            | 118 B         | Only narrow transformations, no shuffle boundary. |\n"
      ],
      "metadata": {
        "id": "0Zqfyw4tNGrG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 2 – Pipeline 2 (GroupBy, Wide Transformation)\n",
        "| Job Id | Stage Id | Description               | Tasks | Input   | Output | Shuffle Read | Shuffle Write | Notes                              |\n",
        "| ------ | -------- | ------------------------- | ----- | ------- | ------ | ------------ | ------------- | ---------------------------------- |\n",
        "| 11     | 14       | PIPELINE_2_GROUPBY_DEVICE | 2/2   | 1.3 MiB | 609 B  | –            | 609 B         | Introduces shuffle due to groupBy. |\n"
      ],
      "metadata": {
        "id": "VJiGVoptNFZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3a – SortMerge Join\n",
        "| Job Id | Stage Id | Description           | Tasks | Input | Output   | Shuffle Read | Shuffle Write | Notes                                        |\n",
        "| ------ | -------- | --------------------- | ----- | ----- | -------- | ------------ | ------------- | -------------------------------------------- |\n",
        "| 25     | 22–25    | PIPELINE_3B_BROADCAST | 3–4/4 | 3 MiB | 64.1 KiB | –            | –             | Broadcast join avoids shuffle, fewer stages. |\n"
      ],
      "metadata": {
        "id": "H008MbdaNXhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 3b – Broadcast Join\n",
        "| Job Id | Stage Id | Description           | Tasks | Input | Output   | Shuffle Read | Shuffle Write | Notes                                        |\n",
        "| ------ | -------- | --------------------- | ----- | ----- | -------- | ------------ | ------------- | -------------------------------------------- |\n",
        "| 25     | 22–25    | PIPELINE_3B_BROADCAST | 3–4/4 | 3 MiB | 64.1 KiB | –            | –             | Broadcast join avoids shuffle, fewer stages. |\n"
      ],
      "metadata": {
        "id": "pXtVugq3NhtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 4 – Multi-Action Pipeline (Caching Impact)\n",
        "\n",
        "| Job Id | Stage Id | Description                          | Tasks | Input  | Output | Notes                                                                     |\n",
        "| ------ | -------- | ------------------------------------ | ----- | ------ | ------ | ------------------------------------------------------------------------- |\n",
        "| 50     | 42–50    | PIPELINE_4_MULTIACTION_WITHOUT_CACHE | 2–4/4 | Varies | Varies | Actions repeated, full recomputation                                      |\n",
        "| 38     | 35–38    | PIPELINE_4_MULTIACTION_WITH_CACHE    | 2–4/4 | Varies | Varies | Cached DataFrame reduces recomputation, fewer stages and faster execution |\n"
      ],
      "metadata": {
        "id": "6jo1INBlNhnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Task 5 – Complex Pipeline\n",
        "\n",
        "| Job Id | Stage Id | Description            | Tasks | Input   | Output   | Shuffle Read | Shuffle Write | Notes                                                                                                    |\n",
        "| ------ | -------- | ---------------------- | ----- | ------- | -------- | ------------ | ------------- | -------------------------------------------------------------------------------------------------------- |\n",
        "| 52     | 102–104  | PIPELINE_5_COMPLEX_AGG | 2–8/8 | 8.9 MiB | 64.1 KiB | –            | –             | Broadcast join avoids shuffle; aggregation and ordering applied; most expensive stage = file scan + join |\n"
      ],
      "metadata": {
        "id": "lBan-I_SNhhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performance Checklist\n",
        "\n",
        " Use broadcast joins when one table is small (<10MB)\n",
        "\n",
        " Cache DataFrames that are reused across actions\n",
        "\n",
        " Minimize shuffles (combine groupBys, filter early)\n",
        "\n",
        " Check Spark UI Stages tab for skew and GC pressure\n",
        "\n",
        " Use .explain() before running to predict stage count"
      ],
      "metadata": {
        "id": "vwi1xn4hNhdi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lbi9hoNOMy3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qSaG-Zc8MrKj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3YRoxUDSJddm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}